{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The purpose of this notebook is to create  create a Machine Learning Classifier to identify True Vs Fake News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Importing datetime\n",
    "from datetime import datetime\n",
    "# Importing matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing re\n",
    "import re\n",
    "# Importing gensim, need to intall it before it can be used.\n",
    "import gensim\n",
    "# Importing spacy, need to install it before it can be used.\n",
    "import spacy\n",
    "# Run in terminal: python -m spacy download en\n",
    "import textstat\n",
    "from textblob import TextBlob\n",
    "#Import statsmodel\n",
    "import statsmodels.api as sm\n",
    "#Import packages for data modeling\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "from preprocess import Preprocesser\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing custom python modules\n",
    "from ml_features import features\n",
    "from ml_pipelines import pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake = pd.read_csv(\"data/Fake.csv\")\n",
    "fake[\"label\"] = 0 #fake news label = 0\n",
    "fake.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As U.S. budget fight looms, Republicans flip t...</td>\n",
       "      <td>WASHINGTON (Reuters) - The head of a conservat...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U.S. military to accept transgender recruits o...</td>\n",
       "      <td>WASHINGTON (Reuters) - Transgender people will...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior U.S. Republican senator: 'Let Mr. Muell...</td>\n",
       "      <td>WASHINGTON (Reuters) - The special counsel inv...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FBI Russia probe helped by Australian diplomat...</td>\n",
       "      <td>WASHINGTON (Reuters) - Trump campaign adviser ...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trump wants Postal Service to charge 'much mor...</td>\n",
       "      <td>SEATTLE/WASHINGTON (Reuters) - President Donal...</td>\n",
       "      <td>politicsNews</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  As U.S. budget fight looms, Republicans flip t...   \n",
       "1  U.S. military to accept transgender recruits o...   \n",
       "2  Senior U.S. Republican senator: 'Let Mr. Muell...   \n",
       "3  FBI Russia probe helped by Australian diplomat...   \n",
       "4  Trump wants Postal Service to charge 'much mor...   \n",
       "\n",
       "                                                text       subject  \\\n",
       "0  WASHINGTON (Reuters) - The head of a conservat...  politicsNews   \n",
       "1  WASHINGTON (Reuters) - Transgender people will...  politicsNews   \n",
       "2  WASHINGTON (Reuters) - The special counsel inv...  politicsNews   \n",
       "3  WASHINGTON (Reuters) - Trump campaign adviser ...  politicsNews   \n",
       "4  SEATTLE/WASHINGTON (Reuters) - President Donal...  politicsNews   \n",
       "\n",
       "                 date  label  \n",
       "0  December 31, 2017       1  \n",
       "1  December 29, 2017       1  \n",
       "2  December 31, 2017       1  \n",
       "3  December 30, 2017       1  \n",
       "4  December 29, 2017       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = pd.read_csv(\"data/True.csv\")\n",
    "real[\"label\"] = 1 # real news label = 1\n",
    "real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>subject</th>\n",
       "      <th>date</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
       "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
       "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 31, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
       "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 30, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
       "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 29, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
       "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
       "      <td>News</td>\n",
       "      <td>December 25, 2017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0   Donald Trump Sends Out Embarrassing New Year’...   \n",
       "1   Drunk Bragging Trump Staffer Started Russian ...   \n",
       "2   Sheriff David Clarke Becomes An Internet Joke...   \n",
       "3   Trump Is So Obsessed He Even Has Obama’s Name...   \n",
       "4   Pope Francis Just Called Out Donald Trump Dur...   \n",
       "\n",
       "                                                text subject  \\\n",
       "0  Donald Trump just couldn t wish all Americans ...    News   \n",
       "1  House Intelligence Committee Chairman Devin Nu...    News   \n",
       "2  On Friday, it was revealed that former Milwauk...    News   \n",
       "3  On Christmas day, Donald Trump announced that ...    News   \n",
       "4  Pope Francis used his annual Christmas Day mes...    News   \n",
       "\n",
       "                date  label  \n",
       "0  December 31, 2017      0  \n",
       "1  December 31, 2017      0  \n",
       "2  December 30, 2017      0  \n",
       "3  December 29, 2017      0  \n",
       "4  December 25, 2017      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df = pd.concat([fake, real])\n",
    "news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44898, 5)\n",
      "Number of labels of news dataset is  [0 1]\n"
     ]
    }
   ],
   "source": [
    "print(news_df.shape)\n",
    "print(\"Number of labels of news dataset is \",news_df[\"label\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Machine Learning Features are defined in ml_features.py module which consists of the feature engineering and splitting the news data into features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexternals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m time\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtextstat\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtextblob\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TextBlob\r\n",
      "\u001b[37m#Import statsmodel\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mstatsmodels\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mapi\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36msm\u001b[39;49;00m\r\n",
      "\u001b[37m#Import packages for data modeling\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CountVectorizer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TfidfTransformer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnaive_bayes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MultinomialNB\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearSVC\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mfeatures\u001b[39;49;00m:\r\n",
      "        \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcalculate_sentiment\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,title):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to calculate the sentiment polarity of news title\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m TextBlob(title).sentiment.polarity\r\n",
      "\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_readability_score\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,text):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to calculate the readability score for the text\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m textstat.flesch_reading_ease(text)\r\n",
      "\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_baseline_features\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,news_df):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to get baseline model features\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        news_df[\u001b[33m'\u001b[39;49;00m\u001b[33mreadability_score\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = news_df.text.apply(\u001b[36mself\u001b[39;49;00m.get_readability_score)\r\n",
      "        news_df[\u001b[33m\"\u001b[39;49;00m\u001b[33mword_count\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] = news_df[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m].apply(\u001b[34mlambda\u001b[39;49;00m x: \u001b[36mlen\u001b[39;49;00m(x.split()))\r\n",
      "        news_df[\u001b[33m'\u001b[39;49;00m\u001b[33msentiment_score\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = news_df.title.apply(\u001b[36mself\u001b[39;49;00m.calculate_sentiment)\r\n",
      "        X = news_df[[\u001b[33m\"\u001b[39;49;00m\u001b[33mreadability_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33mword_count\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m,\u001b[33m\"\u001b[39;49;00m\u001b[33msentiment_score\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]]\r\n",
      "        y = news_df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[34m0.3\u001b[39;49;00m, random_state=\u001b[34m10\u001b[39;49;00m)\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m X_train, X_test, y_train, y_test\r\n",
      "\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mget_pipeline_features_labels\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,news_df):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to create pipeline features and labels\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        X = news_df[[\u001b[33m\"\u001b[39;49;00m\u001b[33mtext\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]]\r\n",
      "        y = news_df[\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]\r\n",
      "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[34m0.3\u001b[39;49;00m, random_state=\u001b[34m10\u001b[39;49;00m)\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m X_train, X_test, y_train, y_test\r\n",
      "    \r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ml_features.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Benchmark Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = Features.get_baseline_features(news_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmarkmodel = LogisticRegression()\n",
    "benchmarkmodel.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.73      0.65      7037\n",
      "           1       0.59      0.42      0.49      6433\n",
      "\n",
      "    accuracy                           0.59     13470\n",
      "   macro avg       0.59      0.58      0.57     13470\n",
      "weighted avg       0.59      0.59      0.58     13470\n",
      "\n",
      "Test Accuracy of Benchmark Model is 0.5864142538975501\n"
     ]
    }
   ],
   "source": [
    "y_pred = benchmarkmodel.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy of Benchmark Model is {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark model used for classifying fake vs true news  has an Accuracy of 58% and Precision of 58% also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682198\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>label</td>      <th>  No. Observations:  </th>   <td> 31428</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td> 31425</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sun, 31 May 2020</td> <th>  Pseudo R-squ.:     </th>   <td>0.01426</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:46:58</td>     <th>  Log-Likelihood:    </th>  <td> -21440.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -21750.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>1.944e-135</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>readability_score</th> <td>   -0.0062</td> <td>    0.000</td> <td>  -21.222</td> <td> 0.000</td> <td>   -0.007</td> <td>   -0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>word_count</th>        <td> 6.763e-05</td> <td> 2.66e-05</td> <td>    2.545</td> <td> 0.011</td> <td> 1.55e-05</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sentiment_score</th>   <td>    0.3140</td> <td>    0.043</td> <td>    7.253</td> <td> 0.000</td> <td>    0.229</td> <td>    0.399</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  label   No. Observations:                31428\n",
       "Model:                          Logit   Df Residuals:                    31425\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sun, 31 May 2020   Pseudo R-squ.:                 0.01426\n",
       "Time:                        12:46:58   Log-Likelihood:                -21440.\n",
       "converged:                       True   LL-Null:                       -21750.\n",
       "Covariance Type:            nonrobust   LLR p-value:                1.944e-135\n",
       "=====================================================================================\n",
       "                        coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "readability_score    -0.0062      0.000    -21.222      0.000      -0.007      -0.006\n",
       "word_count         6.763e-05   2.66e-05      2.545      0.011    1.55e-05       0.000\n",
       "sentiment_score       0.3140      0.043      7.253      0.000       0.229       0.399\n",
       "=====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = sm.Logit(y_train, X_train)\n",
    "result = logit.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above results we see that readability score and sentiment score are correlated to the true news article because of significant coefficient values. The coefficient interpretations are not considered for interpretations because of less accuracy, precision and recall values. However, the benchmark model gives us an intuition about types of features to be considered in the model development."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Machine Learning Model Developement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting features to get features and labels using train and test split\n",
    "X_train, X_test, y_train, y_test = Features.get_pipeline_features_labels(news_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning pipelines are defined in ml_pipelines.py module which consists of the SVC and Naive-Bayes pipelines including the pre-processing steps in a sequential order. The advantage of modularizing the pipeliens was to sequentially apply the list of pre-processing transformations and classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mexternals\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m joblib\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mpipeline\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m time\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtextstat\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtextblob\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TextBlob\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mstatsmodels\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mapi\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36msm\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m CountVectorizer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfeature_extraction\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtext\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m TfidfTransformer\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mmodel_selection\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m train_test_split\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mnaive_bayes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m MultinomialNB\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msvm\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LinearSVC\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinear_model\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m LogisticRegression\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mwrappers\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mscikit_learn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m KerasClassifier\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlayers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Dense, Input, Dropout\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mkeras\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Sequential\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpreprocess\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Preprocesser\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mpipelines\u001b[39;49;00m:\r\n",
      "    \r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_svc_pipeline\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to create SVC classifier pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        pipeline = Pipeline([\r\n",
      "                        (\u001b[33m'\u001b[39;49;00m\u001b[33mvec\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, CountVectorizer(analyzer=\u001b[33m'\u001b[39;49;00m\u001b[33mword\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,       \r\n",
      "                             min_df=\u001b[34m10\u001b[39;49;00m,                      \u001b[37m# minimum reqd occurences of a word \u001b[39;49;00m\r\n",
      "                             stop_words=\u001b[33m'\u001b[39;49;00m\u001b[33menglish\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,           \u001b[37m# remove stop words\u001b[39;49;00m\r\n",
      "                             lowercase=\u001b[34mTrue\u001b[39;49;00m,                 \u001b[37m# convert all words to lowercase\u001b[39;49;00m\r\n",
      "                             token_pattern=\u001b[33m'\u001b[39;49;00m\u001b[33m[a-zA-Z0-9]\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m3,}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),  \r\n",
      "                        (\u001b[33m'\u001b[39;49;00m\u001b[33mtfidf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, TfidfTransformer()),\r\n",
      "                        (\u001b[33m'\u001b[39;49;00m\u001b[33mclassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, LinearSVC())\r\n",
      "                    ])\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m pipeline\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mcreate_nvb_pipeline\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\r\n",
      "        \u001b[33m\"\"\"\u001b[39;49;00m\r\n",
      "\u001b[33m        Function to create Multinomial Naive-Bayes classifier Pipeline\u001b[39;49;00m\r\n",
      "\u001b[33m        \"\"\"\u001b[39;49;00m\r\n",
      "        pipeline = Pipeline([\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mvec\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, CountVectorizer(analyzer=\u001b[33m'\u001b[39;49;00m\u001b[33mword\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,       \r\n",
      "                             min_df=\u001b[34m10\u001b[39;49;00m,                      \u001b[37m# minimum reqd occurences of a word \u001b[39;49;00m\r\n",
      "                             stop_words=\u001b[33m'\u001b[39;49;00m\u001b[33menglish\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,           \u001b[37m# remove stop words\u001b[39;49;00m\r\n",
      "                             lowercase=\u001b[34mTrue\u001b[39;49;00m,                 \u001b[37m# convert all words to lowercase\u001b[39;49;00m\r\n",
      "                             token_pattern=\u001b[33m'\u001b[39;49;00m\u001b[33m[a-zA-Z0-9]\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m3,}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)),  \r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mtfidf\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, TfidfTransformer()),\r\n",
      "        (\u001b[33m'\u001b[39;49;00m\u001b[33mclassifier\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, MultinomialNB()),  \r\n",
      "        ])\r\n",
      "        \u001b[34mreturn\u001b[39;49;00m pipeline\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize ml_pipelines.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pipelines = pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=10,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an SVC pipelines\n",
    "svc_model = Pipelines.create_svc_pipeline()\n",
    "svc_model.fit(X_train[\"text\"],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7037\n",
      "           1       0.99      0.99      0.99      6433\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n",
      "Test Accuracy of SVC Classifier Model is 0.9927988121752042\n"
     ]
    }
   ],
   "source": [
    "y_pred = svc_model.predict(X_test[\"text\"])\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy of SVC Classifier Model is {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=10,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('classifier',\n",
       "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Multinomial-Naive Bayes pipeline\n",
    "nvb_model = Pipelines.create_nvb_pipeline()\n",
    "nvb_model.fit(X_train[\"text\"],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93      7037\n",
      "           1       0.93      0.93      0.93      6433\n",
      "\n",
      "    accuracy                           0.93     13470\n",
      "   macro avg       0.93      0.93      0.93     13470\n",
      "weighted avg       0.93      0.93      0.93     13470\n",
      "\n",
      "Test Accuracy of Multinomial-NaiveBayes Classifier Model is 0.9319970304380104\n"
     ]
    }
   ],
   "source": [
    "y_pred = nvb_model.predict(X_test[\"text\"])\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(\"Test Accuracy of Multinomial-NaiveBayes Classifier Model is {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(optimizer=\"adam\", dropout=0.02):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, activation='relu',input_dim = 1364381))\n",
    "    model.add(Dropout(dropout), )\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model, verbose=1, epochs=5)\n",
    "\n",
    "keras_pipeline = Pipeline([(\"cv\",CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))),\n",
    "                            (\"kc\", keras_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "31428/31428 [==============================] - 1108s 35ms/step - loss: 0.6921 - accuracy: 0.5222\n",
      "Epoch 2/5\n",
      "31428/31428 [==============================] - 1119s 36ms/step - loss: 0.1205 - accuracy: 0.9592\n",
      "Epoch 3/5\n",
      "31428/31428 [==============================] - 1144s 36ms/step - loss: 0.0694 - accuracy: 0.9798\n",
      "Epoch 4/5\n",
      "31428/31428 [==============================] - 1168s 37ms/step - loss: 0.0685 - accuracy: 0.9798\n",
      "Epoch 5/5\n",
      "31428/31428 [==============================] - 1174s 37ms/step - loss: 0.0678 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cv',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1,\n",
       "                                 max_features=None, min_df=0,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('kc',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x1a636cb990>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_pipeline.fit(X_train[\"text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13470/13470 [==============================] - 123s 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_pipeline.predict(X_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_classifier(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] >= 0.5):\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "    return y_pred\n",
    "    \n",
    "y_pred = bin_classifier(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Fully-Connected Feed Foward Model is 0.8703043801039346\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy of Fully-Connected Feed Foward Model is {}\".format(accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model(optimizer=\"adam\", dropout=0.02):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, activation='relu',input_dim = 1364381))\n",
    "    model.add(Dropout(dropout), )\n",
    "    model.add(Dense(20, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "keras_clf = KerasClassifier(build_fn=create_keras_model, verbose=1, epochs=10)\n",
    "\n",
    "keras_pipeline = Pipeline([(\"cv\",CountVectorizer(min_df=0,max_df=1,ngram_range=(1,2))),\n",
    "                           ('tfidf', TfidfTransformer()),\n",
    "                            (\"kc\", keras_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31428/31428 [==============================] - 484s 15ms/step - loss: 0.6923 - accuracy: 0.5232\n",
      "Epoch 2/10\n",
      "31428/31428 [==============================] - 485s 15ms/step - loss: 0.1482 - accuracy: 0.9615\n",
      "Epoch 3/10\n",
      "31428/31428 [==============================] - 484s 15ms/step - loss: 0.0692 - accuracy: 0.9796\n",
      "Epoch 4/10\n",
      "31428/31428 [==============================] - 482s 15ms/step - loss: 0.0687 - accuracy: 0.9798\n",
      "Epoch 5/10\n",
      "31428/31428 [==============================] - 482s 15ms/step - loss: 0.0682 - accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "31428/31428 [==============================] - 482s 15ms/step - loss: 0.0677 - accuracy: 0.9799\n",
      "Epoch 7/10\n",
      "31428/31428 [==============================] - 481s 15ms/step - loss: 0.0676 - accuracy: 0.9799\n",
      "Epoch 8/10\n",
      "31428/31428 [==============================] - 480s 15ms/step - loss: 0.0671 - accuracy: 0.9799\n",
      "Epoch 9/10\n",
      "31428/31428 [==============================] - 482s 15ms/step - loss: 0.0670 - accuracy: 0.9799\n",
      "Epoch 10/10\n",
      "31428/31428 [==============================] - 481s 15ms/step - loss: 0.0672 - accuracy: 0.9799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('cv',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1,\n",
       "                                 max_features=None, min_df=0,\n",
       "                                 ngram_range=(1, 2), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('kc',\n",
       "                 <keras.wrappers.scikit_learn.KerasClassifier object at 0x1a5d3ba990>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_pipeline.fit(X_train[\"text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13470/13470 [==============================] - 109s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = keras_pipeline.predict(X_test[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_classifier(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if(y_pred[i] >= 0.5):\n",
    "            y_pred[i] = 1\n",
    "        else:\n",
    "            y_pred[i] = 0\n",
    "    return y_pred\n",
    "    \n",
    "y_pred = bin_classifier(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Fully-Connected Feed Foward Model is 0.8838158871566444\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy of Fully-Connected Feed Foward Model is {}\".format(accuracy_score(y_pred,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyper-parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_MultinomialNB = Pipeline([('vect', CountVectorizer(analyzer='word',\n",
    "                                                       lowercase=True,\n",
    "                                                        stop_words='english',\n",
    "                                                       token_pattern='[a-zA-Z0-9]{3,}')),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'clf__alpha': np.arange(0.0,0.05,1.05)\n",
    "}\n",
    "\n",
    "grid_nb_clf = GridSearchCV(test_MultinomialNB,parameters,cv=5, n_jobs = 1)\n",
    "_ = grid_nb_clf.fit(X_train[\"text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_nb_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 MultinomialNB(alpha=0.0, class_prior=None, fit_prior=True))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestmultNB = grid_nb_clf.best_estimator_\n",
    "bestmultNB.fit(X_train[\"text\"],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.96      0.94      7037\n",
      "           1       0.96      0.91      0.93      6433\n",
      "\n",
      "    accuracy                           0.94     13470\n",
      "   macro avg       0.94      0.93      0.94     13470\n",
      "weighted avg       0.94      0.94      0.94     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestmultNB.predict(X_test[\"text\"])\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of Multinomial-NaiveBayes Classifier Tuned Model is 0.9358574610244988\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy of Multinomial-NaiveBayes Classifier Tuned Model is {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_svc = Pipeline([('vect', CountVectorizer(analyzer='word',\n",
    "                                              lowercase=True,\n",
    "                                              stop_words='english',\n",
    "                                              token_pattern='[a-zA-Z0-9]{3,}')),\n",
    "                 ('tfidf', TfidfTransformer()),\n",
    "                 ('clf', LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { \n",
    "              'clf__C':[1,10,100]\n",
    "              }\n",
    "\n",
    "grid_svc_clf = GridSearchCV(test_svc, parameters, cv=5, n_jobs = 1)\n",
    "_ = grid_svc_clf.fit(X_train[\"text\"], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_svc_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vect',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=1,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
       "                                 tokenizer=None, vocabulary=None)),\n",
       "                ('tfidf',\n",
       "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
       "                                  sublinear_tf=False, use_idf=True)),\n",
       "                ('clf',\n",
       "                 LinearSVC(C=10, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='squared_hinge', max_iter=1000,\n",
       "                           multi_class='ovr', penalty='l2', random_state=None,\n",
       "                           tol=0.0001, verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlinearSVC = grid_svc_clf.best_estimator_\n",
    "bestlinearSVC.fit(X_train[\"text\"],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      7037\n",
      "           1       0.99      0.99      0.99      6433\n",
      "\n",
      "    accuracy                           0.99     13470\n",
      "   macro avg       0.99      0.99      0.99     13470\n",
      "weighted avg       0.99      0.99      0.99     13470\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = bestlinearSVC.predict(X_test[\"text\"])\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of SVC Classifier Tuned Model is 0.9928730512249443\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy of SVC Classifier Tuned Model is {}\".format(accuracy_score(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models were saved in order to test a few sample news articles to understand how the data is performing on unseen news articles of current affairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./models/nvb_model.joblib']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(benchmarkmodel, './models/benchmarkmodel.joblib')\n",
    "dump(svc_model, './models/svc_model.joblib')\n",
    "dump(nvb_model, './models/nvb_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = load('./models/svc_model.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(memory=None,\n",
      "         steps=[('vec',\n",
      "                 CountVectorizer(analyzer='word', binary=False,\n",
      "                                 decode_error='strict',\n",
      "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
      "                                 input='content', lowercase=True, max_df=1.0,\n",
      "                                 max_features=None, min_df=10,\n",
      "                                 ngram_range=(1, 1), preprocessor=None,\n",
      "                                 stop_words='english', strip_accents=None,\n",
      "                                 token_pattern='[a-zA-Z0-9]{3,}',\n",
      "                                 tokenizer=None, vocabulary=None)),\n",
      "                ('tfidf',\n",
      "                 TfidfTransformer(norm='l2', smooth_idf=True,\n",
      "                                  sublinear_tf=False, use_idf=True)),\n",
      "                ('classifier',\n",
      "                 LinearSVC(C=1.0, class_weight=None, dual=True,\n",
      "                           fit_intercept=True, intercept_scaling=1,\n",
      "                           loss='squared_hinge', max_iter=1000,\n",
      "                           multi_class='ovr', penalty='l2', random_state=None,\n",
      "                           tol=0.0001, verbose=0))],\n",
      "         verbose=False)\n"
     ]
    }
   ],
   "source": [
    "print(svc_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample News Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "sample1 = [\"Trump Signs Executive Order Directed at Social Media Companies After Feud With Twitter\"]\n",
    "y_pred = bestlinearSVC.predict(sample1)\n",
    "# this should be real news - 1\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results and Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model | Accuracy |\n",
    "| --- | --- |\n",
    "| Benchmark Logistic Regression | 58.64% |\n",
    "| Multinomial Naive-Bayes | 93.12% |\n",
    "| Linear SVC | 99% |\n",
    "| Tuned Multinomial Naive-Bayes | 93.58% |\n",
    "| Tuned Linear SVC | 99.28% |\n",
    "| Fully Connected Feed-Forward Model (1-hidden layer – 50 nodes, dropout – 0.02, Adam optimizer) | 87.3% |\n",
    "| Fully Connected Feed-Forward Model (1-hidden layer – 20 nodes, dropout – 0.02, Adam optimizer) | 88% |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus based on the above model results we chose the Tuned Linear SVC Model due to Out-of-Sample Accuracy of 99.28%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
